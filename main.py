# -*- coding: utf-8 -*-
"""tomato_diseases_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ApmjZ_PhoBuBtwaHy3p4gfH4j3TOFAVY
"""

#install kaggle
# !pip install -q kaggle

# from google.colab import files
# files.upload()

# Commented out IPython magic to ensure Python compatibility.
#change the working directory
# % cd /content/drive/MyDrive/Colab Notebooks/tomato_dis_cls

#create a directory
# !mkdir ~/.kaggle

#copy the json file into created directory
# !cp kaggle.json ~/.kaggle/

#change the permission of json to act
# ! chmod 600 ~/.kaggle/kaggle.json

#download dataset
# !kaggle datasets download -d noulam/tomato

# !unzip tomato.zip

#start for my tomato diseases classification end to end project.
# first install the tensorflow library
# !pip install tensorflow-gpu

# !nvidia-smi

# !pip install glob

#check the version of tensorflow
import tensorflow as tf
# tf.__version__

#import the required library
from tensorflow.keras.layers import Input,Dense,Lambda,Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.applications.inception_v3 import preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img
from tensorflow.keras.models import Sequential
import numpy as np
from glob import glob

#reshize your image
image_size = [224,224]
train = "archive (1)/New Plant Diseases Dataset(Augmented)//train"
test = "archive (1)/New Plant Diseases Dataset(Augmented)//valid"

inception = InceptionV3(input_shape=image_size+[3],weights='imagenet',include_top=False)

# don't train existing weight
for layer in inception.layers:
  layer.trainable = False

# getting helpful for getting output classes
folders = glob('archive (1)//New Plant Diseases Dataset(Augmented)//train/*')

#our lyr
x = Flatten()(inception.output)

prediction = Dense(len(folders),activation='softmax')(x)
# create  model
model = Model(inputs=inception.input,outputs=prediction)

# summerize your model
model.summary()

#compile model
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

#use the image data generator to import the images from the dataset
train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1./255)

training_set = train_datagen.flow_from_directory(train,target_size=(224,224),batch_size=32, class_mode='categorical')

test_set = test_datagen.flow_from_directory(test,target_size=(224,224),batch_size=32,class_mode='categorical')

# fit the model
r = model.fit(training_set,validation_data=test_set,epochs=5,steps_per_epoch=len(training_set),validation_steps=len(test_set))
model.save('tomato_disease.h5')
